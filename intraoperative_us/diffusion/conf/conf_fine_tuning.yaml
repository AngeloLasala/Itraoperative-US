dataset_params:
  # parent directory of the dataset
  # local path: 
  #            1) "/media/angelo/OS/Users/lasal/OneDrive - Scuola Superiore Sant'Anna/PhD_notes/Visiting_Imperial/RESECT_iUS_dataset/dataset"
  #            2) cineca: '/leonardo_work/IscrC_Med-LMGM/Angelo/ius_data/dataset'
  dataset_path: "/leonardo_work/IscrC_Med-LMGM/Angelo/ius_data/dataset"  
  im_channels : 1
  im_size_h : 256         # 256
  im_size_w : 256         # 256 
  splitting_seed: 42      # sedd for set reprodicitbilityin random splitting
  train_percentage: 0.8              # percentage of the dataset used for training
  val_percentage: 0.1                # percentage of the dataset used for validation
  test_percentage: 0.1               # percentage of the dataset used for testing
  splitting_json: "splitting.json"   # FOR REPRODUCIBILITY: name of the json file containing the splitting


autoencoder_params:
   ## 'scratch' -> old version,
   ## '/home/angelo/Documenti/Itraoperative-US/intraoperative_us/diffusion/models/vae/AutoencoderKL_SD1.5_default' -> architecture from huggingface
   ## cineca: '/leonardo_work/IscrC_Med-LMGM/Angelo/Itraoperative-US/intraoperative_us/diffusion/models/vae/AutoencoderKL_SD1.5_default'
  autoencoder_type: '/leonardo_work/IscrC_Med-LMGM/Angelo/Itraoperative-US/intraoperative_us/diffusion/models/vae/AutoencoderKL_SD1.5_default'         
  ## 'random' -> random initialization, 
  ## 'SD1.5'  -> SD1.5 initialization,
  ## 'only_D' -> E from SD1.5 and D pre-training
  initialization: 'only_D'               ## 'random' -> random initialization, 'SD1.5' -> SD1.5 initialization
  z_channels: 4
  codebook_size : 20
  down_channels : [128, 256, 512, 512]    # original [128, 256, 512, 512] - small [64, 128, 256, 256]
  mid_channels : [256, 256]
  down_sample : [True, True, True]
  attn_down : [False, False, False]
  norm_channels: 32
  num_heads: 16
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2
  condition_config:
    condition_types: []                     # could be also ['class', 'text', 'image' ]: PUT THE DEFAULT VALUE AS 'image'
    text_condition_config:
      text_embed_model: 'clip'
      train_text_embed_model: False
      text_embed_dim: 512
      cond_drop_prob: 0.1
    image_condition_config:                 ## this is for the image conditioning - seg/heatmaps stacked on the input
      image_condition_input_channels:  1    # total number of spatial channels in the conditional heatmaps
      image_condition_output_channels: 3
      image_condition_h : 256
      image_condition_w : 256
      cond_drop_prob: 0.1
    class_condition_config :               ## this is for the class conditioning of different type of hypertrophy 
      num_classes : 4                      # numebr of classes, for now it is 4
      cond_drop_prob : 0.1                 # probability of dropping class labels

diffusion_params:
  num_timesteps : 1000
  beta_start : 0.0015
  beta_end : 0.0195

ldm_params:
  down_channels: [ 128, 256, 256, 256]
  mid_channels: [ 256, 256 ]
  down_sample: [ True, True, True]
  attn_down : [True, True, True]
  time_emb_dim: 256
  norm_channels: 32
  num_heads: 8
  conv_out_channels : 128
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2
  condition_config:
    condition_types: [ 'image' ]      # could be also ['class', 'text', 'image' ]: PUT THE DEFAULT VALUE AS 'image'
    text_condition_config:
      text_embed_model: 'clip'
      train_text_embed_model: False
      text_embed_dim: 512
      cond_drop_prob: 0.1
    image_condition_config:                 ## this is for the image conditioning - seg/heatmaps stacked on the input
      image_condition_input_channels: 1     # total number of spatial channels in the segmentation maps
      image_condition_output_channels: 3
      image_condition_h : 256
      image_condition_w : 256
      cond_drop_prob: 0.1
    class_condition_config :     ## this is for the class conditioning of different type of hypertrophy 
      num_classes : 4           # numebr of classes, for now it is 4
      cond_drop_prob : 0.1       # probability of dropping class labels


train_params:
  seed : 1111
  ldm_batch_size: 8
  ldm_batch_size_sample: 32
  autoencoder_batch_size: 8   # 2: local for shape (240,320) - 4 or 8: cineca for shape (240, 320)
  disc_start: 8
  disc_weight: 0.5
  codebook_weight: 1
  commitment_beta: 0.2
  perceptual_weight: 1
  kl_weight: 0.000005
  ldm_epochs : 3000
  autoencoder_epochs : 100
  num_samples : 25
  num_grid_rows : 5
  ldm_lr: 0.00001
  autoencoder_lr: 0.0001
  autoencoder_acc_steps : 1
  autoencoder_img_save_steps : 8
  save_frequency : 300